做RAG需要自己准备一个txt文档，新建一个docs文件夹，放进去。例如，这里放了一个./docs/问答手册.txt

```python
# 从指定文件读取，输入为List
from llama_index.core import SimpleDirectoryReader,Document
documents = SimpleDirectoryReader(input_files=['./docs/问答手册.txt']).load_data()
```


方法一：Documents可以直接构建index
```python
# 构建向量索引
from llama_index.core import VectorStoreIndex
index = VectorStoreIndex.from_documents(documents,embed_model=embedding)
# 想要看到进度条的话，加一个参数 show_progress=True
# index = VectorStoreIndex.from_documents(documents,embed_model=embedding,show_progress=True)
```

方法二：可以先构建节点，再构建索引，同时采用faiss作为向量存储库
```python
# 构建节点
from llama_index.core.node_parser import SentenceSplitter
transformations = [SentenceSplitter(chunk_size = 512)]

from llama_index.core.ingestion.pipeline import run_transformations
nodes = run_transformations(documents, transformations=transformations)
```

根据节点构建索引
```python
# 构建索引
from llama_index.vector_stores.faiss import FaissVectorStore
import faiss
from llama_index.core import StorageContext, VectorStoreIndex

# 从上一节得知，智谱embedding-2的维度是1024
dimensions = len(emb)
vector_store = FaissVectorStore(faiss_index=faiss.IndexFlatL2(dimensions))
storage_context = StorageContext.from_defaults(vector_store=vector_store)

index = VectorStoreIndex(
    nodes = nodes,
    storage_context=storage_context,
    embed_model = embedding,
)
```

这样索引就算是建成了。我们可以把索引存储到硬盘，这样以后就不用重复构建，直接从硬盘读取。

```python
# save index to disk
persist_dir = "./storage"
index.storage_context.persist(persist_dir)
```

如果之前有保存过索引到硬盘，可以直接读取。
```python
# load index from disk
from llama_index.vector_stores.faiss import FaissVectorStore
import faiss
from llama_index.core import StorageContext, load_index_from_storage
vector_store = FaissVectorStore.from_persist_dir(persist_dir)
storage_context = StorageContext.from_defaults(
    vector_store=vector_store, persist_dir=persist_dir
)
index = load_index_from_storage(storage_context=storage_context,embed_model = embedding)
```

index可以直接做问答引擎。

```python
query_engine = index.as_query_engine(llm=llm)
# 回答提问
response = query_engine.query("专利申请如何收费？")
response
```

response.text 中是回答的文本。response.source_nodes是检索到的文本块儿，每个文本块都有score，代表与问题的相关性，由向量计算得出。

方法三：我们也可以先构建索引器，再构建合成器，再组装成问答引擎。

```python
# 构建检索器
from llama_index.core.retrievers import VectorIndexRetriever
# 想要自定义参数，可以构造参数字典
kwargs = {'similarity_top_k': 5, 'index': index, 'dimensions': dimensions} # 必要参数
retriever = VectorIndexRetriever(**kwargs)
```

```python
# 构建合成器
from llama_index.core.response_synthesizers  import get_response_synthesizer
response_synthesizer = get_response_synthesizer(llm=llm)
```

```python
# 构建问答引擎
from llama_index.core.query_engine import RetrieverQueryEngine
engine = RetrieverQueryEngine(
      retriever=retriever,
      response_synthesizer=response_synthesizer
        )
```

```python
# 提问
question = "请问商标注册需要提供哪些文件？"
answer = engine.query(question)
print(answer.response)
```

在商标注册中，对于企业来说，需要提供的文件包括：
- 被申请人提供的营业执照复印件；
- 授权委托书；
- 商标图案的电子版；
- 具体商品或服务的名称。

若是国内自然人申请商标，则需提供以下文件：
- 个体工商户档案及自然人身份证复印件；
- 授权委托书；
- 商标图案的电子版；
- 具体商品或服务的名称。

国外自然人则需要提供：
- 护照；
- 授权委托书；
- 及商标图案的电子版；
- 具体商品或服务的名称。

### 方法四：利用Qdrant向量库

先安装一下

```bash
%pip install qdrant-client
%pip install llama-index-vector-stores-qdrant
%pip install llama-index-readers-file
```
加载文档
```python
import qdrant_client
from llama_index.core import SimpleDirectoryReader

# load documents
documents = SimpleDirectoryReader(
    input_files=['./docs/问答手册.txt']
).load_data()

print("Document ID:", documents[0].doc_id)
```
Document ID: 02572b3e-18f7-4b5e-b432-3e1ed9ba89b8

构建索引
```python
# Create an index over the documents
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.qdrant import QdrantVectorStore

# 连接Qdrant，并保存在本地的qdrant文件夹中
qclient = qdrant_client.QdrantClient(path="qdrant")
vector_store = QdrantVectorStore(client=qclient, collection_name="wenda")
storage_context = StorageContext.from_defaults(vector_store=vector_store)
index = VectorStoreIndex.from_documents(
    documents, 
    storage_context=storage_context,
    embed_model = embedding
)
```
构建检索器
```python
# 构建检索器
from llama_index.core.retrievers import VectorIndexRetriever
# 想要自定义参数，可以构造参数字典
kwargs = {'similarity_top_k': 5, 'index': index, 'dimensions': dimensions} # 必要参数
retriever = VectorIndexRetriever(**kwargs)
```

构建合成器
```python
# 构建合成器
from llama_index.core.response_synthesizers  import get_response_synthesizer
response_synthesizer = get_response_synthesizer(llm=llm)
```
构建问答引擎
```python
# 构建问答引擎
from llama_index.core.query_engine import RetrieverQueryEngine
engine = RetrieverQueryEngine(
      retriever=retriever,
      response_synthesizer=response_synthesizer,
        )
```

提问
```python
# 提问
question = "What are the applications of Agent AI systems ?"
answer = engine.query(question)
print(answer.response)
```
Agent AI systems have a variety of applications, which include:

1. Interactive AI: Enhancing user interactions and providing personalized experiences.
2. Content Generation: Assisting in the creation of content for bots and AI agents, which can be used in various applications such as customer service or storytelling.
3. Productivity: Improving productivity in applications by enabling tasks like replaying events, paraphrasing information, predicting actions, and synthesizing scenarios (both 3D and 2D).
4. Healthcare: Ethical deployment in sensitive domains like healthcare, which could potentially improve diagnoses and patient care while also addressing health disparities.
5. Gaming Industry: Transforming the role of developers by shifting focus from scripting non-player characters to refining agent learning processes.
6. Robotics and Manufacturing: Redefining manufacturing roles and requiring new skill sets, rather than replacing human workers, as adaptive robotic systems are developed.
7. Simulation: Learning collaboration policies within simulated environments, which can be applied to the real world with careful consideration and safety measures.


