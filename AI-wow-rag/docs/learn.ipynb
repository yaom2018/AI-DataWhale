{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package           Version\n",
      "----------------- -----------\n",
      "asttokens         2.4.1\n",
      "colorama          0.4.6\n",
      "comm              0.2.2\n",
      "debugpy           1.8.8\n",
      "decorator         5.1.1\n",
      "exceptiongroup    1.2.2\n",
      "executing         2.1.0\n",
      "ipykernel         6.29.5\n",
      "ipython           8.29.0\n",
      "jedi              0.19.2\n",
      "jupyter_client    8.6.3\n",
      "jupyter_core      5.7.2\n",
      "matplotlib-inline 0.1.7\n",
      "nest-asyncio      1.6.0\n",
      "packaging         24.2\n",
      "parso             0.8.4\n",
      "pip               22.0.4\n",
      "platformdirs      4.3.6\n",
      "prompt_toolkit    3.0.48\n",
      "psutil            6.1.0\n",
      "pure_eval         0.2.3\n",
      "Pygments          2.18.0\n",
      "python-dateutil   2.9.0.post0\n",
      "pywin32           308\n",
      "pyzmq             26.2.0\n",
      "setuptools        58.1.0\n",
      "six               1.16.0\n",
      "stack-data        0.6.3\n",
      "tornado           6.4.1\n",
      "traitlets         5.14.3\n",
      "typing_extensions 4.12.2\n",
      "wcwidth           0.2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\NLP\\Python\\try-rag\\rag\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting faiss-cpu\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/10/3a/4b00c7076581795d8337e51dc65d1a1271b04f07c14b3de01cd32bb9ee96/faiss_cpu-1.9.0-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "     --------------------------------------- 14.9/14.9 MB 21.8 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/48/76/154ebda6794faf0b0f3ccb1b5cd9a19f0a63cb9e1f3d2c61b6114002677b/scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 22.6 MB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e7/1c/8daa6df17a945cb1a2a1e3bae3c49643f7b3b94017ff01a4787064f03f84/scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "     --------------------------------------- 44.8/44.8 MB 17.7 MB/s eta 0:00:00\n",
      "Collecting numpy<3.0,>=1.25.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8e/8b/1c131ab5a94c1086c289c6e1da1d843de9dbd95fe5f5ee6e61904c9518e2/numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     --------------------------------------- 12.9/12.9 MB 17.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, faiss-cpu, scikit-learn\n",
      "Successfully installed faiss-cpu-1.9.0 joblib-1.4.2 numpy-2.1.3 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting openai\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/30/90/7f6621a79de8b32f120e9790441c24dd9afafb2f1ca41fd3b9f4faaf8f9f/openai-1.54.5-py3-none-any.whl (389 kB)\n",
      "     -------------------------------------- 389.5/389.5 KB 1.9 MB/s eta 0:00:00\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e4/f5/f2b75d2fc6f1a260f340f0e7c6a060f4dd2961cc16884ed851b0d18da06a/anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.4/90.4 KB 1.0 MB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/56/95/9377bcb415797e44274b51d46e3249eba641711cf3348050f76ee7b15ffc/httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 KB 4.1 MB/s eta 0:00:00\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b6/1b/79d038a632e2d00657ca4965b6f93454eb0e563ad9168f40050f320e5460/jiter-0.7.1-cp310-none-win_amd64.whl (201 kB)\n",
      "     -------------------------------------- 201.7/201.7 KB 3.0 MB/s eta 0:00:00\n",
      "Collecting sniffio\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "     -------------------------------------- 434.9/434.9 KB 6.8 MB/s eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting tqdm>4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2b/78/57043611a16c655c8350b4c01b8d6abfb38cc2acb475238b62c2146186d7/tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.6/78.6 KB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Collecting idna>=2.8\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.4/70.4 KB 4.0 MB/s eta 0:00:00\n",
      "Collecting certifi\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/12/90/3c9ff0512038035f59d279fddeb79f5f1eccd8859f06d6163c58798b9487/certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "     -------------------------------------- 167.3/167.3 KB 9.8 MB/s eta 0:00:00\n",
      "Collecting httpcore==1.*\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.6/78.6 KB 4.3 MB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/de/81/7dfe464eca78d76d31dd661b04b5f2036ec72ea8848dd87ab7375e185c23/pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 20.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Installing collected packages: tqdm, sniffio, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 certifi-2024.8.30 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 idna-3.10 jiter-0.7.1 openai-1.54.5 pydantic-2.9.2 pydantic-core-2.23.4 sniffio-1.3.1 tqdm-4.67.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting python-dotenv\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZHIPU_API_KEY')\n",
    "base_url = \"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "emb_model = \"embedding-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    api_key = api_key,\n",
    "    base_url = base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_text = \"\"\"\n",
    "Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\n",
    "\n",
    "However, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\n",
    "\n",
    "For examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\n",
    "\n",
    "Furthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\n",
    "\n",
    "We will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chunk_size = 150\n",
    "chunks = [embedding_text[i:i + chunk_size] for i in range(0, len(embedding_text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "embeddings = []\n",
    "for chunk in chunks:\n",
    "    response = client.embeddings.create(\n",
    "        model=emb_model,\n",
    "        input=chunk,\n",
    "    )\n",
    "    embeddings.append(response.data[0].embedding)\n",
    "normalized_embeddings = normalize(np.array(embeddings).astype('float32'))\n",
    "d = len(embeddings[0])\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(normalized_embeddings)\n",
    "\n",
    "n_vectors = index.ntotal\n",
    "\n",
    "print(n_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "def match_text(input_text, index, chunks, k=2):\n",
    "    k = min(k, len(chunks))\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=emb_model,\n",
    "        input=input_text,\n",
    "    )\n",
    "    input_embedding = response.data[0].embedding\n",
    "    input_embedding = normalize(np.array([input_embedding]).astype('float32'))\n",
    "\n",
    "    distances, indices = index.search(input_embedding, k)\n",
    "    matching_texts = \"\"\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        print(f\"similarity: {distances[0][i]:.4f}\\nmatching text: \\n{chunks[idx]}\\n\")\n",
    "        matching_texts += f\"similarity: {distances[0][i]:.4f}\\nmatching text: \\n{chunks[idx]}\\n\"\n",
    "\n",
    "    return matching_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity: 0.7497\n",
      "matching text: \n",
      "ystem and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to de\n",
      "\n",
      "similarity: 0.7120\n",
      "matching text: \n",
      "mental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What are the applications of Agent AI systems ?\"\n",
    "\n",
    "matched_texts = match_text(input_text=input_text, index=index, chunks=chunks, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity: 0.7497\\nmatching text: \\nystem and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to de\\nsimilarity: 0.7120\\nmatching text: \\nmental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empat\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "根据找到的文档\n",
    "{matched_texts}\n",
    "生成\n",
    "{input_text}\n",
    "的答案，尽可能使用文档语句的原文回答。不要复述问题，直接开始回答。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_stream(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,  # 填写需要调用的模型名称\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    if response:\n",
    "        for chunk in response:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent AI systems can be applied in various ways, including the development of new methods to systemize and customize such systems. These systems can also contribute to mental advances in agent AI, which in turn help towards these goals and enable many to benefit from a greater understanding of how to model embodied and empathetic agents."
     ]
    }
   ],
   "source": [
    "\n",
    "get_completion_stream(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama-index-core in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (0.10.15)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (2.0.36)\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (2.1.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (6.0.2)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (0.1.19)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (1.2.15)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (2024.10.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (3.9.1)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (3.4.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (8.5.0)\n",
      "Requirement already satisfied: pandas in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (2.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (3.11.4)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (11.0.0)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (0.6.7)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (0.27.2)\n",
      "Requirement already satisfied: openai>=1.1.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (1.54.5)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (0.8.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core) (4.12.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (0.2.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core) (2.9.2)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core) (1.0.7)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core) (2024.8.30)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (2024.11.6)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (1.4.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core) (0.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core) (1.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core) (3.23.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core) (2024.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting llama-index-embeddings-zhipuai\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/af/5b62fbc4256f00173b35e14bb406415f4202d2d323adda3991d9ba142ce2/llama_index_embeddings_zhipuai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/54/24/cad9153b5aa715ac5b9d079e2474ec846f85dc90136e86e1ea0aed800967/llama_index_core-0.12.1-py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 4.4 MB/s eta 0:00:00\n",
      "Collecting zhipuai<3.0.0.0,>=2.1.5.20230904\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/10/28/5c1efbfb560e64458b22e0442279af8bde673edcb096762a3aeccee3a8ec/zhipuai-2.1.5.20230904-py3-none-any.whl (104 kB)\n",
      "     -------------------------------------- 105.0/105.0 KB 5.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.6.7)\n",
      "Requirement already satisfied: nltk>3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (3.9.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (3.11.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2.32.3)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2.9.2)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (3.4.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (8.5.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.0.8)\n",
      "Collecting filetype<2.0.0,>=1.2.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (4.67.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (6.0.2)\n",
      "Requirement already satisfied: wrapt in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.16.0)\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2.1.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.9.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.6.0)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.27.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2024.10.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.2.15)\n",
      "Requirement already satisfied: pydantic-core>=2.14.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from zhipuai<3.0.0.0,>=2.1.5.20230904->llama-index-embeddings-zhipuai) (2.23.4)\n",
      "Collecting pyjwt<2.9.0,>=2.8.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Collecting cachetools>=4.2.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.17.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (24.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.2.0)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.3.1)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.0.7)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.14.0)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-zhipuai) (1.2.2)\n",
      "Installing collected packages: filetype, pyjwt, cachetools, zhipuai, llama-index-core, llama-index-embeddings-zhipuai\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.15\n",
      "    Uninstalling llama-index-core-0.10.15:\n",
      "      Successfully uninstalled llama-index-core-0.10.15\n",
      "Successfully installed cachetools-5.5.0 filetype-1.2.0 llama-index-core-0.12.1 llama-index-embeddings-zhipuai-0.2.0 pyjwt-2.8.0 zhipuai-2.1.5.20230904\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-vector-stores-faiss 0.1.1 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.1 which is incompatible.\n",
      "llama-index-readers-file 0.1.4 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.1 which is incompatible.\n",
      "llama-index-llms-openai 0.1.8 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.1 which is incompatible.\n",
      "llama-index-embeddings-openai 0.1.5 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting llama-index-llms-zhipuai\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/39/27/887fbb4b05f72110f15332faaf77453eedca23a56684bff227ba4b9e62f5/llama_index_llms_zhipuai-0.2.1-py3-none-any.whl (5.5 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-llms-zhipuai) (0.12.1)\n",
      "Requirement already satisfied: zhipuai<3.0.0.0,>=2.1.5.20230904 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-llms-zhipuai) (2.1.5.20230904)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (3.4.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.8.0)\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2.1.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (8.5.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.6.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2.9.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (3.11.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (4.12.2)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.27.2)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.2.15)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.16.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (6.0.2)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2024.10.0)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.6.7)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.2.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (11.0.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2.0.36)\n",
      "Requirement already satisfied: nltk>3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (3.9.1)\n",
      "Requirement already satisfied: pyjwt<2.9.0,>=2.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from zhipuai<3.0.0.0,>=2.1.5.20230904->llama-index-llms-zhipuai) (2.8.0)\n",
      "Requirement already satisfied: pydantic-core>=2.14.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from zhipuai<3.0.0.0,>=2.1.5.20230904->llama-index-llms-zhipuai) (2.23.4)\n",
      "Requirement already satisfied: cachetools>=4.2.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from zhipuai<3.0.0.0,>=2.1.5.20230904->llama-index-llms-zhipuai) (5.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (24.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.17.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2.4.3)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.0.7)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2024.8.30)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.14.0)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2024.11.6)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (8.1.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic<2.10.0,>=2.7.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-zhipuai) (1.2.2)\n",
      "Installing collected packages: llama-index-llms-zhipuai\n",
      "Successfully installed llama-index-llms-zhipuai-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama-index-readers-file in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-readers-file) (0.0.2)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-readers-file) (1.24.14)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-readers-file) (4.3.1)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c9/bb/524971a3f038701b8751b71f0ff825a8df82c0f511d3860cb58a8fe93045/llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
      "Requirement already satisfied: pandas in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.2.3)\n",
      "Requirement already satisfied: pydantic<3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.9.2)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.6.0)\n",
      "Requirement already satisfied: wrapt in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.16.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.0.36)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.7)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.9.0)\n",
      "Collecting numpy<2.0.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/19/77/538f202862b9183f54108557bfda67e17603fc560c384559e769321c9d92/numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.32.3)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.10.0)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (11.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.67.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.5.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.2.15)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.11.4)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.4.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.4.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.1.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.17.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.11.6)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.23.1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.7)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.6.2.post1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.2.2)\n",
      "Installing collected packages: numpy, llama-index-core\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] 拒绝访问。: 'E:\\\\NLP\\\\Python\\\\try-rag\\\\rag\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libscipy_openblas64_-c16e4918366c6bc1f1cd71e28ca36fc0.dll'\n",
      "Check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llama-index-vector-stores-faiss in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (0.1.1)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c9/bb/524971a3f038701b8751b71f0ff825a8df82c0f511d3860cb58a8fe93045/llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2024.10.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.32.3)\n",
      "Requirement already satisfied: wrapt in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (8.5.0)\n",
      "Requirement already satisfied: pandas in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.2.3)\n",
      "Requirement already satisfied: pydantic<3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.9.2)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.27.2)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.2.15)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.0.36)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.9.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (6.0.2)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.4.2)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.6.7)\n",
      "Requirement already satisfied: numpy<2.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (11.0.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.11.4)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.0.8)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (4.67.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.17.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (24.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (6.1.0)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.4.2)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.23.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (3.23.1)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.3.1)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (0.14.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss) (1.2.2)\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.12.1\n",
      "    Uninstalling llama-index-core-0.12.1:\n",
      "      Successfully uninstalled llama-index-core-0.12.1\n",
      "Successfully installed llama-index-core-0.10.68.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-zhipuai 0.2.1 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n",
      "llama-index-embeddings-zhipuai 0.2.0 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.10.68.post1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llamaindex-py-client in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (0.1.19)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client) (2.9.2)\n",
      "Requirement already satisfied: httpx>=0.20.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client) (0.27.2)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client) (1.0.7)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client) (2024.8.30)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client) (1.3.1)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->llamaindex-py-client) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client) (2.23.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx>=0.20.0->llamaindex-py-client) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-core\n",
    "%pip install llama-index-embeddings-zhipuai\n",
    "%pip install llama-index-llms-zhipuai\n",
    "%pip install llama-index-readers-file\n",
    "%pip install llama-index-vector-stores-faiss\n",
    "%pip install llamaindex-py-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZHIPU_API_KEY')\n",
    "base_url = \"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "emb_model = \"embedding-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt_tab: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.zhipuai import ZhipuAI\n",
    "llm = ZhipuAI(\n",
    "    api_key = api_key,\n",
    "    model = chat_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个名为 ChatGLM 的人工智能助手，是基于清华大学 KEG 实验室和智谱 AI 公司于 2024 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。\n"
     ]
    }
   ],
   "source": [
    "# 测试对话模型\n",
    "response = llm.complete(\"你是谁？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置嵌入模型\n",
    "from llama_index.embeddings.zhipuai import ZhipuAIEmbedding\n",
    "embedding = ZhipuAIEmbedding(\n",
    "    api_key = api_key,\n",
    "    model = emb_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, list)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试嵌入模型\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "len(emb), type(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZHIPU_API_KEY')\n",
    "base_url = \"https://open.bigmodel.cn/api/paas/v4/\"\n",
    "chat_model = \"glm-4-flash\"\n",
    "emb_model = \"embedding-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt_tab: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import Field  # 导入Field，用于Pydantic模型中定义字段的元数据\n",
    "from typing import Optional, List, Mapping, Any\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import SimpleDirectoryReader, SummaryIndex\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    CompletionResponseGen,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurLLM(CustomLLM):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_name: str = Field(default=chat_model)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(self, api_key: str, base_url: str, model_name: str = chat_model, **data: Any):\n",
    "        super().__init__(**data)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)  # 使用传入的api_key和base_url初始化 client 实例\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        response = self.client.chat.completions.create(model=self.model_name, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            response_text = response.choices[0].message.content\n",
    "            return CompletionResponse(text=response_text)\n",
    "        else:\n",
    "            raise Exception(f\"Unexpected response format: {response}\")\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        response = self.client.chat.completions.create(model=self.model_name, messages=[{\"role\": \"user\", \"content\": prompt}], stream=True)\n",
    "        if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            for choice in response.choices:\n",
    "                content = choice.delta.content\n",
    "                yield CompletionResponse(text=content, delta=content)\n",
    "        else:\n",
    "            raise Exception(f\"Unexpected response format: {response}\")\n",
    "\n",
    "# 测试对话模型\n",
    "llm = OurLLM(api_key=api_key, base_url=base_url, model_name=chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个名为 ChatGLM 的人工智能助手，是基于清华大学 KEG 实验室和智谱 AI 公司于 2024 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。\n"
     ]
    }
   ],
   "source": [
    "response = llm.complete(\"你是谁？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, list)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 配置Embedding模型\n",
    "from typing import Any, List\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "class OurEmbeddings(BaseEmbedding):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_name: str = Field(default=emb_model)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str = api_key, \n",
    "        base_url: str = base_url,\n",
    "        model_name: str = emb_model,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url) \n",
    "\n",
    "    def invoke_embedding(self, query: str) -> List[float]:\n",
    "        response = self.client.embeddings.create(model=self.model_name, input=[query])\n",
    "\n",
    "        # 检查响应是否成功\n",
    "        if response.data and len(response.data) > 0:\n",
    "            return response.data[0].embedding\n",
    "        else:\n",
    "            raise ValueError(\"Failed to get embedding from ZhipuAI API\")\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        return self.invoke_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        return self.invoke_embedding(text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._get_text_embedding(text) for text in texts]\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._get_text_embeddings(texts)\n",
    "\n",
    "embedding = OurEmbeddings(api_key=api_key, base_url=base_url, model_name=emb_model)\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "len(emb), type(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(input_files=['./docs/问答手册.txt']).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "index = VectorStoreIndex.from_documents(documents,embed_model=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = \"./storage\"\n",
    "index.storage_context.persist(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent AI systems can be applied in interactive AI, content generation for bots and AI agents, productivity applications like replaying, paraphrasing, action prediction, and synthesizing 3D or 2D scenarios. They can also contribute to health topic analysis, transform roles in the gaming industry by refining agent learning processes, redefine manufacturing roles through adaptive robotic systems, and assist in learning collaboration policies in simulation.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "# 回答提问\n",
    "response = query_engine.query(\"What are the applications of Agent AI systems ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "transformations = [SentenceSplitter(chunk_size = 512)]\n",
    "\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "nodes = run_transformations(documents, transformations=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建索引\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "vector_store = FaissVectorStore(faiss_index=faiss.IndexFlatL2(1024))\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes = nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model = embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = \"./storage\"\n",
    "index.storage_context.persist(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "vector_store = FaissVectorStore.from_persist_dir(persist_dir)\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=persist_dir\n",
    ")\n",
    "index = load_index_from_storage(storage_context=storage_context,embed_model = embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建检索器\n",
    "dimensions = len(emb)\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "# 想要自定义参数，可以构造参数字典\n",
    "kwargs = {'similarity_top_k': 5, 'index': index, 'dimensions': dimensions} # 必要参数\n",
    "retriever = VectorIndexRetriever(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers  import get_response_synthesizer\n",
    "response_synthesizer = get_response_synthesizer(llm=llm)\n",
    "# 构建问答引擎\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "engine = RetrieverQueryEngine(\n",
    "      retriever=retriever,\n",
    "      response_synthesizer=response_synthesizer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent AI systems can be applied in various domains such as content generation for bots and AI agents, productivity enhancement, replaying and paraphrasing content, action prediction, synthesizing 3D and 2D scenarios, health topic analysis, gaming industry transformation, and adaptive robotic systems in manufacturing. They can also contribute to learning collaboration policies in simulations.\n"
     ]
    }
   ],
   "source": [
    "# 提问\n",
    "question = \"What are the applications of Agent AI systems ?\"\n",
    "answer = engine.query(question)\n",
    "print(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'061539ee-ff3b-4113-a766-f3039b697c62': TextNode(id_='061539ee-ff3b-4113-a766-f3039b697c62', embedding=None, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7e163de9-6172-497d-a1fd-dfbbb648b441', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='a72c530c59da935d4a73b9d2e59a02d80f7618f736f9b52d75fbeab091523145'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bd6460b9-e046-4ad5-8760-6c89a187eba7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5128f538caf583931f5dcc7bd0d013dd356a78f5eaf21fb9dae1dba236603900')}, text='Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\\r\\n\\r\\nHowever, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\\r\\n\\r\\nFor examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways.', start_char_idx=0, end_char_idx=2736, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), 'bd6460b9-e046-4ad5-8760-6c89a187eba7': TextNode(id_='bd6460b9-e046-4ad5-8760-6c89a187eba7', embedding=None, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7e163de9-6172-497d-a1fd-dfbbb648b441', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='a72c530c59da935d4a73b9d2e59a02d80f7618f736f9b52d75fbeab091523145'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='061539ee-ff3b-4113-a766-f3039b697c62', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='9753ffda7b697335fd17f10798d641e4f23cd27b3013960ea0cd252c0b8d7a39')}, text='2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', start_char_idx=1615, end_char_idx=3353, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')}\n"
     ]
    }
   ],
   "source": [
    "print(index.docstore.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '061539ee-ff3b-4113-a766-f3039b697c62', '1': 'bd6460b9-e046-4ad5-8760-6c89a187eba7'}\n"
     ]
    }
   ],
   "source": [
    "print(index.index_struct.nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'7e163de9-6172-497d-a1fd-dfbbb648b441': RefDocInfo(node_ids=['061539ee-ff3b-4113-a766-f3039b697c62', 'bd6460b9-e046-4ad5-8760-6c89a187eba7'], metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'})}\n"
     ]
    }
   ],
   "source": [
    "print(index.ref_doc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='bd6460b9-e046-4ad5-8760-6c89a187eba7', embedding=None, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7e163de9-6172-497d-a1fd-dfbbb648b441', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='a72c530c59da935d4a73b9d2e59a02d80f7618f736f9b52d75fbeab091523145'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='061539ee-ff3b-4113-a766-f3039b697c62', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='9753ffda7b697335fd17f10798d641e4f23cd27b3013960ea0cd252c0b8d7a39')}, text='2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', start_char_idx=1615, end_char_idx=3353, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docstore.get_node('bd6460b9-e046-4ad5-8760-6c89a187eba7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.docstore.delete_document('bd6460b9-e046-4ad5-8760-6c89a187eba7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "transformations = [SentenceSplitter(chunk_size = 512)]\n",
    "\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "nodes = run_transformations(documents, transformations=transformations)\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"author\": \"Stephen King\",\n",
    "            \"theme\": \"Friendship\",\n",
    "            \"year\": 1994,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"director\": \"Francis Ford Coppola\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1972,\n",
    "        },\n",
    "    )\n",
    "]\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造流式输出引擎\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=True, \n",
    "    similarity_top_k=3,\n",
    "    llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting fastapi\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/54/c4/148d5046a96c428464557264877ae5a9338a83bbe0df045088749ec89820/fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.9/94.9 KB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from fastapi) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from fastapi) (4.12.2)\n",
      "Collecting starlette<0.42.0,>=0.40.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/00/2b325970b3060c7cecebab6d295afe763365822b1306a12eeab198f74323/starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "     -------------------------------------- 73.2/73.2 KB 807.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from starlette<0.42.0,>=0.40.0->fastapi) (4.6.2.post1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Installing collected packages: starlette, fastapi\n",
      "Successfully installed fastapi-0.115.5 starlette-0.41.3\n"
     ]
    }
   ],
   "source": [
    "%pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting uvicorn\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/eb/14/78bd0e95dd2444b6caacbca2b730671d4295ccb628ef58b81bee903629df/uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "     -------------------------------------- 63.7/63.7 KB 490.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: click>=7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from uvicorn) (4.12.2)\n",
      "Requirement already satisfied: h11>=0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Installing collected packages: uvicorn\n",
      "Successfully installed uvicorn-0.32.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个专注于学习和协作的人工智能助手。"
     ]
    }
   ],
   "source": [
    "response_stream = query_engine.query(\"你是谁？\") \n",
    "for text in response_stream.response_gen:\n",
    "    print(text,end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [8224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63947 - \"GET /stream_chat?param=%E4%BD%A0%E5%A5%BD HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [8224]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import StreamingResponse\n",
    "app = FastAPI()\n",
    "app.add_middleware(CORSMiddleware,allow_origins=[\"*\"])\n",
    "@app.get('/stream_chat')\n",
    "async def stream_chat(param:str = \"你好\"):\n",
    "    async def generate():  \n",
    "        # 我们假设query_engine已经构建完成\n",
    "        response_stream = query_engine.query(param) \n",
    "        for text in response_stream.response_gen:\n",
    "            yield text\n",
    "    return StreamingResponse(generate(), media_type='text/event-stream')  \n",
    "if __name__ == '__main__':\n",
    "    #uvicorn.run(app, host='0.0.0.0', port=5000)\n",
    "    config = uvicorn.Config(app, host='0.0.0.0', port=5000)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
