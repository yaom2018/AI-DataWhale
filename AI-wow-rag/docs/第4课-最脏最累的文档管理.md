文档管理意味着对保存在硬盘上的index进行增删改查。我们先来看看针对faiss向量存储的管理方式。

查看index下面的所有文档
```python
print(index.docstore.docs)
```

查看index下面的所有node的id
```python
print(index.index_struct.nodes_dict)
```

查看index下面所有有ref的文档的信息
```python
print(index.ref_doc_info)
```

查看任意给定id的node详细信息
```python
index.docstore.get_node('51595901-ebe3-48b5-b57b-dc8794ef4556')
# 或者 index.docstore.docs['51595901-ebe3-48b5-b57b-dc8794ef4556']
```


删除一个节点，删除这个操作尽量不要尝试，可能会导致后面的代码运行出错。
```python
# index.docstore.delete_document('51595901-ebe3-48b5-b57b-dc8794ef4556')
```


新增节点
```python
index.insert_nodes([doc_single])
```
注意这里的doc_single必须是一个 TextNode 对象。例如上文查看node时输出的那个。
TextNode 对象也可以自己构造。构造方式为：

```python
from llama_index.core.schema import TextNode
nodes = [
    TextNode(
        text="The Shawshank Redemption",
        metadata={
            "author": "Stephen King",
            "theme": "Friendship",
            "year": 1994,
        },
    ),
    TextNode(
        text="The Godfather",
        metadata={
            "director": "Francis Ford Coppola",
            "theme": "Mafia",
            "year": 1972,
        },
    )
]
index.insert_nodes(nodes)
```

或者仿照前一节课的从文档构造节点的方式。
```python
# 从指定文件读取，输入为List
from llama_index.core import SimpleDirectoryReader,Document
documents = SimpleDirectoryReader(input_files=['./docs/另一个手册.txt']).load_data()
from llama_index.core.node_parser import SentenceSplitter
transformations = [SentenceSplitter(chunk_size = 512)]

from llama_index.core.ingestion.pipeline import run_transformations
nodes = run_transformations(documents, transformations=transformations)
index.insert_nodes(nodes)
```
至于改的话，没有很方便的方式。先删除再新增吧。


